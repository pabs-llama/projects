{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import shapiro \n",
    "from scipy.stats import lognorm\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import imblearn\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from statistics import mean, stdev\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wines = pd.read_csv(\"winequality-red.csv\", sep = \";\")\n",
    "white_wines = pd.read_csv(\"winequality-white.csv\", sep =\";\")\n",
    "\n",
    "# formatting\n",
    "red_wines.columns= red_wines.columns.str.replace(' ','_')\n",
    "white_wines.columns = white_wines.columns.str.replace(' ','_')\n",
    "\n",
    "#Quality categories\n",
    "red_wines ['quality_label'] = red_wines['quality'].apply(lambda value: 'low' if value <= 5 \n",
    "                                                        else 'medium' if value <= 7 \n",
    "                                                        else 'high')\n",
    "\n",
    "red_wines['quality_label'] = pd.Categorical(red_wines['quality_label'],\n",
    "categories=['low', 'medium', 'high'])\n",
    "\n",
    "white_wines ['quality_label'] = white_wines['quality'].apply(lambda value: 'low' if value <= 5 \n",
    "                                                        else 'medium' if value <= 7 \n",
    "                                                        else 'high')\n",
    "\n",
    "white_wines[\"quality_label\"] = pd.Categorical(white_wines[\"quality_label\"], categories = [\"low\",\"medium\",\"high\"])\n",
    "\n",
    "# Type of wine categories\n",
    "red_wines [\"type\"] = 'Red Wine'\n",
    "red_wines['type'] = pd.Categorical(red_wines['type'],\n",
    "categories=[\"Red Wine\",\"White Wine\"])\n",
    "\n",
    "white_wines [\"type\"] = 'White Wine'\n",
    "white_wines['type'] = pd.Categorical(white_wines['type'],\n",
    "categories=[\"Red Wine\",\"White Wine\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest- unfiltered data set- smote after split- normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7776923076923077"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# merge datasets\n",
    "white_and_red = pd.merge(red_wines, white_wines, how = \"outer\")\n",
    "\n",
    "# Encoding\n",
    "enc = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "white_and_red['quality_label_encoded'] = enc.fit_transform(white_and_red[['quality_label']])\n",
    "\n",
    "#Feauture / Target split\n",
    "X=white_and_red.drop([\"type\",\"quality_label\",\"quality\",\"quality_label_encoded\"], axis=1)\n",
    "y= white_and_red[\"quality_label_encoded\"]\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Smote\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "## standarization\n",
    "norm = MinMaxScaler().fit(X_train_resampled)\n",
    "\n",
    "# transform training data\n",
    "X_train_resampled_norm = norm.transform(X_train_resampled)\n",
    "\n",
    "# transform testing data\n",
    "X_test_norm = norm.transform(X_test)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(X_train_resampled_norm, y_train_resampled)\n",
    "\n",
    "RF_preds = RF_clf.predict(X_test_norm)\n",
    "\n",
    "RF_acc = accuracy_score(y_test, RF_preds)\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest- Filtered data set with iqr- smote after split- normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white wine shape;  (4898, 14) \n",
      "filtered white wine shape:  (4015, 14)\n",
      "red wine shape;  (1599, 14) \n",
      "filtered red wine shape:  (1194, 14)\n"
     ]
    }
   ],
   "source": [
    "# filtered outliers\n",
    "white_wines_clean= white_wines.drop(\"quality\", axis=1)\n",
    "numeric_columns_white = white_wines_clean.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "white_wine_filtered= white_wines.copy()\n",
    "for column in numeric_columns_white.columns:\n",
    "        q1 = np.quantile(numeric_columns_white[column], 0.25)\n",
    "        q3 = np.quantile(numeric_columns_white[column], 0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        # Filter rows based on the column's outlier range\n",
    "        white_wine_filtered = white_wine_filtered[(white_wine_filtered[column] >= lower) & (white_wine_filtered[column] <= upper)]\n",
    "print(\"white wine shape; \", white_wines.shape, \"\\nfiltered white wine shape: \", white_wine_filtered.shape)\n",
    "\n",
    "red_wines_clean= red_wines.drop(\"quality\", axis=1)\n",
    "numeric_columns_red = red_wines_clean.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "red_wine_filtered= red_wines.copy()\n",
    "for column in numeric_columns_red.columns: \n",
    "        q1 = np.quantile(numeric_columns_red[column], 0.25)\n",
    "        q3 = np.quantile(numeric_columns_red[column], 0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        # Filter rows based on the column's outlier range\n",
    "        red_wine_filtered = red_wine_filtered[(red_wine_filtered[column] >= lower) & (red_wine_filtered[column] <= upper)]\n",
    "print(\"red wine shape; \", red_wines.shape, \"\\nfiltered red wine shape: \", red_wine_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "red_wine_filtered[\"residual_sugar\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792706333973128"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge datasets\n",
    "\n",
    "white_and_red_filtered = pd.merge(red_wine_filtered, white_wine_filtered, how = \"outer\")\n",
    "\n",
    "# Encoding\n",
    "enc = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "white_and_red_filtered['quality_label_encoded'] = enc.fit_transform(white_and_red_filtered[['quality_label']])\n",
    "\n",
    "#Feauture / Target split\n",
    "X_filtered=white_and_red_filtered.drop([\"type\",\"quality_label\",\"quality\",\"quality_label_encoded\"], axis=1)\n",
    "y_filtered= white_and_red_filtered[\"quality_label_encoded\"]\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "#Smote\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled_filtered, y_train_resampled_filtered = smote.fit_resample(X_train_filtered, y_train_filtered)\n",
    "\n",
    "## standarization\n",
    "norm = MinMaxScaler().fit(X_train_resampled_filtered)\n",
    "\n",
    "# transform training data\n",
    "X_train_resampled_filtered_norm = norm.transform(X_train_resampled_filtered)\n",
    "\n",
    "# transform testing data\n",
    "X_test_resampled_filtered_norm = norm.transform(X_test_filtered)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(X_train_resampled_filtered_norm, y_train_resampled_filtered)\n",
    "\n",
    "RF_preds = RF_clf.predict(X_test_resampled_filtered_norm)\n",
    "\n",
    "RF_acc = accuracy_score(y_test_filtered, RF_preds)\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White_and_red shape:  (6497, 15)\n",
      "X_filtered:  (5209, 11)\n",
      "X_train_filtered:  (4167, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"White_and_red shape: \", white_and_red.shape)\n",
    "print(\"X_filtered: \", X_filtered.shape)\n",
    "print(\"X_train_filtered: \", X_train_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest- Filtered data set with zscore- smote after split- normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtering with z score\n",
    "\n",
    "# create a copy of the columns(numeric values only) to iterate over ( if not it iterates over the newly created as well)\n",
    "\n",
    "\n",
    "\n",
    "white_wines_clean= white_wines.drop(\"quality\", axis=1)\n",
    "numeric_columns = white_wines_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "ww_filtered= white_wines.copy()\n",
    "z_score_dict = {}\n",
    "for x in numeric_columns:\n",
    "    z_score_dict[f'z_score_{x}'] = zscore(white_wines[x])\n",
    "\n",
    "\n",
    "# Create a DataFrame from the z_score_dict\n",
    "z_score_df = pd.DataFrame(z_score_dict, index=white_wines.index)\n",
    "\n",
    "# Concatenate the original DataFrame with the z_score DataFrame\n",
    "\n",
    "white_wines_with_zscores = pd.concat([ww_filtered, z_score_df], axis=1)\n",
    "\n",
    "# # Filter rows where the absolute value of all z_scores is less than 3\n",
    "z_score_columns = z_score_df.columns\n",
    "filtered_white_wines_z = white_wines_with_zscores[(white_wines_with_zscores[z_score_columns].abs() < 3).all(axis=1)]\n",
    "\n",
    "\n",
    "red_wines_clean= red_wines.drop(\"quality\", axis=1)\n",
    "numeric_columns_red = red_wines_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "rw_filtered= red_wines.copy()\n",
    "z_score_dict_red = {}\n",
    "for x in numeric_columns_red:\n",
    "    z_score_dict_red[f'z_score_{x}'] = zscore(red_wines[x])\n",
    "\n",
    "\n",
    "# Create a DataFrame from the z_score_dict\n",
    "z_score_df_red = pd.DataFrame(z_score_dict_red, index=red_wines.index)\n",
    "\n",
    "# Concatenate the original DataFrame with the z_score DataFrame\n",
    "\n",
    "red_wines_with_zscores = pd.concat([rw_filtered, z_score_df_red], axis=1)\n",
    "\n",
    "# # Filter rows where the absolute value of all z_scores is less than 3\n",
    "z_score_columns_red = z_score_df_red.columns\n",
    "filtered_red_wines_z = red_wines_with_zscores[(red_wines_with_zscores[z_score_columns_red].abs() < 3).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7751677852348994"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge datasets\n",
    "white_and_red_filtered_z = pd.merge(filtered_white_wines_z, filtered_red_wines_z, how = \"outer\")\n",
    "\n",
    "# Encoding\n",
    "enc = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "white_and_red_filtered_z['quality_label_encoded'] = enc.fit_transform(white_and_red_filtered_z[['quality_label']])\n",
    "\n",
    "#Feauture / Target split\n",
    "X_filtered_z=white_and_red_filtered_z.drop([\"type\",\"quality_label\",\"quality\",\"quality_label_encoded\"], axis=1)\n",
    "y_filtered_z= white_and_red_filtered_z[\"quality_label_encoded\"]\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train_filtered_z, X_test_filtered_z, y_train_filtered_z, y_test_filtered_z = train_test_split(\n",
    "    X_filtered_z, y_filtered_z, test_size=0.2, random_state=42)\n",
    "\n",
    "#Smote\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled_filtered_z, y_train_resampled_filtered_z = smote.fit_resample(X_train_filtered_z, y_train_filtered_z)\n",
    "\n",
    "## standarization\n",
    "norm = MinMaxScaler().fit(X_train_resampled_filtered_z)\n",
    "\n",
    "# transform training data\n",
    "X_train_resampled_filtered_norm_z = norm.transform(X_train_resampled_filtered_z)\n",
    "\n",
    "# transform testing data\n",
    "X_test_resampled_filtered_norm_z = norm.transform(X_test_filtered_z)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(X_train_resampled_filtered_norm_z, y_train_resampled_filtered_z)\n",
    "\n",
    "RF_preds = RF_clf.predict(X_test_resampled_filtered_norm_z)\n",
    "\n",
    "RF_acc = accuracy_score(y_test_filtered_z, RF_preds)\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest- Filtered data set with iqr- (no smote) standarization (robust scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.809021113243762"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# copy of datasets\n",
    "X_train_stand = X_train_filtered.copy()\n",
    "X_test_stand = X_test_filtered.copy()\n",
    "\n",
    "scale = StandardScaler().fit(X_train_stand)\n",
    "    \n",
    "# transform the training data column\n",
    "X_train_stand = scale.transform(X_train_stand)\n",
    "    \n",
    "# transform the testing data column\n",
    "X_test_stand = scale.transform(X_test_stand)\n",
    "\n",
    "\n",
    "# ## standarization\n",
    "# norm = MinMaxScaler().fit(X_train_resampled_filtered)\n",
    "\n",
    "# # transform training data\n",
    "# X_train_resampled_filtered_norm = norm.transform(X_train_resampled_filtered)\n",
    "\n",
    "# # transform testing data\n",
    "# X_test_resampled_filtered_norm = norm.transform(X_test_filtered)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(X_train_stand, y_train_filtered)\n",
    "\n",
    "RF_preds = RF_clf.predict(X_test_stand)\n",
    "\n",
    "RF_acc = accuracy_score(y_test_filtered, RF_preds)\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest- Filtered data set with iqr- smote - standarization (robust scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7783109404990403"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy of datasets\n",
    "X_train_stand_resampled = X_train_resampled_filtered.copy()\n",
    "X_test_stand = X_test_filtered.copy()\n",
    "\n",
    "scale = StandardScaler().fit(X_train_stand_resampled)\n",
    "    \n",
    "# transform the training data column\n",
    "X_train_stand_resampled = scale.transform(X_train_stand_resampled)\n",
    "    \n",
    "# transform the testing data column\n",
    "X_test_stand = scale.transform(X_test_stand)\n",
    "\n",
    "\n",
    "# ## standarization\n",
    "# norm = MinMaxScaler().fit(X_train_resampled_filtered)\n",
    "\n",
    "# # transform training data\n",
    "# X_train_resampled_filtered_norm = norm.transform(X_train_resampled_filtered)\n",
    "\n",
    "# # transform testing data\n",
    "# X_test_resampled_filtered_norm = norm.transform(X_test_filtered)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(X_train_stand_resampled, y_train_resampled_filtered)\n",
    "\n",
    "RF_preds = RF_clf.predict(X_test_stand)\n",
    "\n",
    "RF_acc = accuracy_score(y_test_filtered, RF_preds)\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest with SMOTE (after split) & Stratified K-fold cross validation -normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracy: [0.8854961832061069, 0.8676844783715013, 0.8854961832061069, 0.8956743002544529, 0.8955414012738854, 0.8993630573248408, 0.8777070063694268, 0.8929936305732484, 0.8968152866242038, 0.913375796178344]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 91.3375796178344 %\n",
      "\n",
      "Minimum Accuracy: 86.76844783715013 %\n",
      "\n",
      "Overall Accuracy: 89.10147323382117 %\n",
      "\n",
      "Standard Deviation is: 0.012612963211940435\n",
      "\n",
      "Maximum Cohen-Kappa score that can be obtained from this model is: 87.01 %\n",
      "\n",
      "Maximum Balanced Accuracy That can be obtained from this model is: 91.33 %\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE (only on train set)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_filtered, y_train_filtered)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(X_resampled) # normalizes for all X, instead of dividing in train and test.scaling after smote\n",
    "\n",
    "# Create  classifier object.\n",
    "# lr = linear_model.LogisticRegression()\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "  \n",
    "# Create StratifiedKFold object.\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "lst_balanced_accuracy_score=[]\n",
    "lst_kappa= []\n",
    "\n",
    "# .split generates indices to split data into training and test set.\n",
    "for train_index, test_index in skf.split(X_resampled,y_resampled):  \n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    rf.fit(x_train_fold, y_train_fold)\n",
    "    rf_pred = rf.predict(x_test_fold)\n",
    "    kappa = cohen_kappa_score(rf_pred, y_test_fold)\n",
    "    lst_kappa.append(round(kappa, 4))\n",
    "    balanced_acc_sc = balanced_accuracy_score(y_test_fold, rf_pred)\n",
    "    lst_balanced_accuracy_score.append(round(balanced_acc_sc,4))\n",
    "    lst_accu_stratified.append(rf.score(x_test_fold, y_test_fold))\n",
    "  \n",
    "# Print the output.\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "print('\\nMaximum Cohen-Kappa score that can be obtained from this model is:',\n",
    "      max(lst_kappa)*100, '%')\n",
    "print('\\nMaximum Balanced Accuracy That can be obtained from this model is:',\n",
    "      max(lst_balanced_accuracy_score)*100, '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: Random forest with SMOTE, Normalization & Stratified K-fold cross validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.89      0.89       262\n",
      "         1.0       0.89      0.85      0.87       261\n",
      "         2.0       0.96      1.00      0.98       262\n",
      "\n",
      "    accuracy                           0.91       785\n",
      "   macro avg       0.91      0.91      0.91       785\n",
      "weighted avg       0.91      0.91      0.91       785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Classification report\n",
    "print(\"Classification Report: Random forest with SMOTE, Normalization & Stratified K-fold cross validation\")\n",
    "print(classification_report(y_test_fold, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest with SMOTE (after split) & Stratified K-fold cross validation -standarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracy: [0.8956743002544529, 0.8727735368956743, 0.8791348600508906, 0.8880407124681934, 0.8993630573248408, 0.8929936305732484, 0.8738853503184714, 0.8866242038216561, 0.9070063694267516, 0.9197452229299363]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 91.97452229299363 %\n",
      "\n",
      "Minimum Accuracy: 87.27735368956743 %\n",
      "\n",
      "Overall Accuracy: 89.15241244064116 %\n",
      "\n",
      "Standard Deviation is: 0.01479230552629917\n",
      "\n",
      "Maximum Cohen-Kappa score that can be obtained from this model is: 87.96000000000001 %\n",
      "\n",
      "Maximum Balanced Accuracy That can be obtained from this model is: 91.97 %\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# standarize\n",
    "\n",
    "scale = preprocessing.StandardScaler()\n",
    "x_scaled = scale.fit_transform(X_resampled) #  for all X, instead of dividing in train and test.scaling after smote\n",
    "\n",
    "# Create  classifier object.\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "  \n",
    "# Create StratifiedKFold object.\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "lst_balanced_accuracy_score=[]\n",
    "lst_kappa= []\n",
    "\n",
    "# .split generates indices to split data into training and test set.\n",
    "for train_index, test_index in skf.split(X_resampled,y_resampled):  \n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    rf.fit(x_train_fold, y_train_fold)\n",
    "    rf_pred = rf.predict(x_test_fold)\n",
    "    kappa = cohen_kappa_score(rf_pred, y_test_fold)\n",
    "    lst_kappa.append(round(kappa, 4))\n",
    "    balanced_acc_sc = balanced_accuracy_score(y_test_fold, rf_pred)\n",
    "    lst_balanced_accuracy_score.append(round(balanced_acc_sc,4))\n",
    "    lst_accu_stratified.append(rf.score(x_test_fold, y_test_fold))\n",
    "  \n",
    "# Print the output.\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "print('\\nMaximum Cohen-Kappa score that can be obtained from this model is:',\n",
    "      max(lst_kappa)*100, '%')\n",
    "print('\\nMaximum Balanced Accuracy That can be obtained from this model is:',\n",
    "      max(lst_balanced_accuracy_score)*100, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_resampled shape:  (7854, 11)\n",
      "X_train shape:  (4167, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_resampled shape: \",X_resampled.shape)\n",
    "print(\"X_train shape: \", X_train_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: Random forest with SMOTE, Standarisation & Stratified K-fold cross validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.90      0.90       262\n",
      "         1.0       0.90      0.87      0.88       261\n",
      "         2.0       0.96      1.00      0.98       262\n",
      "\n",
      "    accuracy                           0.92       785\n",
      "   macro avg       0.92      0.92      0.92       785\n",
      "weighted avg       0.92      0.92      0.92       785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Classification report\n",
    "print(\"Classification Report: Random forest with SMOTE, Standarisation & Stratified K-fold cross validation\")\n",
    "print(classification_report(y_test_fold, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest with SMOTE & Undersampling / standarized / Stratified K-fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "over = SMOTE(random_state=42) # (sampling_strategy=0.1)\n",
    "under = RandomUnderSampler() #(sampling_strategy=0.5)\n",
    "steps = [('over', over), ('under', under), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracy: [0.7937649880095923, 0.8081534772182254, 0.7985611510791367, 0.8105515587529976, 0.8393285371702638, 0.8057553956834532, 0.8513189448441247, 0.8341346153846154, 0.8028846153846154, 0.8125]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 85.13189448441247 %\n",
      "\n",
      "Minimum Accuracy: 79.37649880095923 %\n",
      "\n",
      "Overall Accuracy: 81.56953283527024 %\n",
      "\n",
      "Standard Deviation is: 0.019144370833007154\n",
      "\n",
      "Maximum Cohen-Kappa score that can be obtained from this model is: 67.52 %\n",
      "\n",
      "Maximum Balanced Accuracy That can be obtained from this model is: 74.88 %\n"
     ]
    }
   ],
   "source": [
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# standarize\n",
    "\n",
    "scale = preprocessing.StandardScaler()\n",
    "x_scaled = scale.fit_transform(X_filtered) # normalizes for all X, instead of dividing in train and test.scaling after smote\n",
    "\n",
    "# Create  classifier object.\n",
    "# rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "  \n",
    "# Create StratifiedKFold object.\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "lst_balanced_accuracy_score=[]\n",
    "lst_kappa= []\n",
    "\n",
    "# .split generates indices to split data into training and test set.\n",
    "for train_index, test_index in skf.split(X_train_filtered,y_train_filtered):  \n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_filtered[train_index], y_filtered[test_index]\n",
    "    pipeline.fit(x_train_fold, y_train_fold)\n",
    "    pipeline_pred = pipeline.predict(x_test_fold)\n",
    "    kappa = cohen_kappa_score(pipeline_pred, y_test_fold)\n",
    "    lst_kappa.append(round(kappa, 4))\n",
    "    balanced_acc_sc = balanced_accuracy_score(y_test_fold, pipeline_pred)\n",
    "    lst_balanced_accuracy_score.append(round(balanced_acc_sc,4))\n",
    "    lst_accu_stratified.append(pipeline.score(x_test_fold, y_test_fold))\n",
    "  \n",
    "# Print the output.\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "print('\\nMaximum Cohen-Kappa score that can be obtained from this model is:',\n",
    "      max(lst_kappa)*100, '%')\n",
    "print('\\nMaximum Balanced Accuracy That can be obtained from this model is:',\n",
    "      max(lst_balanced_accuracy_score)*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine quality per type of wine with random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## white wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792706333973128"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding\n",
    "enc = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "white_wine_filtered['quality_label_encoded'] = enc.fit_transform(white_wine_filtered[['quality_label']])\n",
    "\n",
    "#Feauture / Target split\n",
    "Xw_filtered=white_wine_filtered.drop([\"type\",\"quality_label\",\"quality\",\"quality_label_encoded\"], axis=1)\n",
    "yw_filtered= white_wine_filtered[\"quality_label_encoded\"]\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "Xw_train_filtered, Xw_test_filtered, yw_train_filtered, yw_test_filtered = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "#Smote\n",
    "smote = SMOTE(random_state=42)\n",
    "Xw_train_resampled_filtered, yw_train_resampled_filtered = smote.fit_resample(Xw_train_filtered, yw_train_filtered)\n",
    "\n",
    "## standarization\n",
    "norm = MinMaxScaler().fit(Xw_train_resampled_filtered)\n",
    "\n",
    "# transform training data\n",
    "Xw_train_resampled_filtered_norm = norm.transform(Xw_train_resampled_filtered)\n",
    "\n",
    "# transform testing data\n",
    "Xw_test_resampled_filtered_norm = norm.transform(Xw_test_filtered)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(Xw_train_resampled_filtered_norm, yw_train_resampled_filtered)\n",
    "\n",
    "RFw_preds = RF_clf.predict(Xw_test_resampled_filtered_norm)\n",
    "\n",
    "RFw_acc = accuracy_score(yw_test_filtered, RFw_preds)\n",
    "RFw_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracy: [0.8918575063613231, 0.8676844783715013, 0.8867684478371501, 0.8893129770992366, 0.889171974522293, 0.8853503184713376, 0.8764331210191083, 0.8853503184713376, 0.9019108280254777, 0.9095541401273886]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 90.95541401273886 %\n",
      "\n",
      "Minimum Accuracy: 86.76844783715013 %\n",
      "\n",
      "Overall Accuracy: 88.83394110306155 %\n",
      "\n",
      "Standard Deviation is: 0.011723619731660608\n",
      "\n",
      "Maximum Cohen-Kappa score that can be obtained from this model is: 86.42999999999999 %\n",
      "\n",
      "Maximum Balanced Accuracy That can be obtained from this model is: 90.95 %\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "Xw_resampled, yw_resampled = smote.fit_resample(Xw_train_filtered, yw_train_filtered)\n",
    "\n",
    "# standarize\n",
    "\n",
    "scale = preprocessing.StandardScaler()\n",
    "xw_scaled = scale.fit_transform(Xw_resampled) # standarization for all X, instead of dividing in train and test.scaling after smote\n",
    "\n",
    "# Create  classifier object.\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "  \n",
    "# Create StratifiedKFold object.\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "lst_balanced_accuracy_score=[]\n",
    "lst_kappa= []\n",
    "\n",
    "# .split generates indices to split data into training and test set.\n",
    "for train_index, test_index in skf.split(Xw_resampled,yw_resampled):  \n",
    "    x_train_fold, x_test_fold = xw_scaled[train_index], xw_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = yw_resampled[train_index], yw_resampled[test_index]\n",
    "    rf.fit(x_train_fold, y_train_fold)\n",
    "    rf_pred = rf.predict(x_test_fold)\n",
    "    kappa = cohen_kappa_score(rf_pred, y_test_fold)\n",
    "    lst_kappa.append(round(kappa, 4))\n",
    "    balanced_acc_sc = balanced_accuracy_score(y_test_fold, rf_pred)\n",
    "    lst_balanced_accuracy_score.append(round(balanced_acc_sc,4))\n",
    "    lst_accu_stratified.append(rf.score(x_test_fold, y_test_fold))\n",
    "  \n",
    "# Print the output.\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "print('\\nMaximum Cohen-Kappa score that can be obtained from this model is:',\n",
    "      max(lst_kappa)*100, '%')\n",
    "print('\\nMaximum Balanced Accuracy That can be obtained from this model is:',\n",
    "      max(lst_balanced_accuracy_score)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: Random forest with SMOTE & Stratified K-fold cross validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.89      0.89       262\n",
      "         1.0       0.88      0.85      0.86       261\n",
      "         2.0       0.95      1.00      0.97       262\n",
      "\n",
      "    accuracy                           0.91       785\n",
      "   macro avg       0.91      0.91      0.91       785\n",
      "weighted avg       0.91      0.91      0.91       785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Classification report\n",
    "print(\"Classification Report: Random forest with SMOTE & Stratified K-fold cross validation\")\n",
    "print(classification_report(y_test_fold, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## red wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7573221757322176"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding\n",
    "enc = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "red_wine_filtered['quality_label_encoded'] = enc.fit_transform(red_wine_filtered[['quality_label']])\n",
    "\n",
    "#Feauture / Target split\n",
    "Xr_filtered=red_wine_filtered.drop([\"type\",\"quality_label\",\"quality\",\"quality_label_encoded\"], axis=1)\n",
    "yr_filtered= red_wine_filtered[\"quality_label_encoded\"]\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "Xr_train_filtered, Xr_test_filtered, yr_train_filtered, yr_test_filtered = train_test_split(\n",
    "    Xr_filtered, yr_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "#Smote\n",
    "smote = SMOTE(random_state=42)\n",
    "Xr_train_resampled_filtered, yr_train_resampled_filtered = smote.fit_resample(Xr_train_filtered, yr_train_filtered)\n",
    "\n",
    "## standarization\n",
    "norm = MinMaxScaler().fit(Xr_train_resampled_filtered)\n",
    "\n",
    "# transform training data\n",
    "Xr_train_resampled_filtered_norm = norm.transform(Xr_train_resampled_filtered)\n",
    "\n",
    "# transform testing data\n",
    "Xr_test_resampled_filtered_norm = norm.transform(Xr_test_filtered)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(Xr_train_resampled_filtered_norm, yr_train_resampled_filtered)\n",
    "\n",
    "RFr_preds = RF_clf.predict(Xr_test_resampled_filtered_norm)\n",
    "\n",
    "RFr_acc = accuracy_score(yr_test_filtered, RFr_preds)\n",
    "RFr_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeacademy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
