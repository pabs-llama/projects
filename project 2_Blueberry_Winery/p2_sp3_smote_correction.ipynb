{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import shapiro \n",
    "from scipy.stats import lognorm\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import imblearn\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from statistics import mean, stdev\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wines = pd.read_csv(\"winequality-red.csv\", sep = \";\")\n",
    "white_wines = pd.read_csv(\"winequality-white.csv\", sep =\";\")\n",
    "\n",
    "# formatting\n",
    "red_wines.columns= red_wines.columns.str.replace(' ','_')\n",
    "white_wines.columns = white_wines.columns.str.replace(' ','_')\n",
    "\n",
    "#Quality categories\n",
    "red_wines ['quality_label'] = red_wines['quality'].apply(lambda value: 'low' if value <= 5 \n",
    "                                                        else 'medium' if value <= 7 \n",
    "                                                        else 'high')\n",
    "\n",
    "red_wines['quality_label'] = pd.Categorical(red_wines['quality_label'],\n",
    "categories=['low', 'medium', 'high'])\n",
    "\n",
    "white_wines ['quality_label'] = white_wines['quality'].apply(lambda value: 'low' if value <= 5 \n",
    "                                                        else 'medium' if value <= 7 \n",
    "                                                        else 'high')\n",
    "\n",
    "white_wines[\"quality_label\"] = pd.Categorical(white_wines[\"quality_label\"], categories = [\"low\",\"medium\",\"high\"])\n",
    "\n",
    "# Type of wine categories\n",
    "red_wines [\"type\"] = 'Red Wine'\n",
    "red_wines['type'] = pd.Categorical(red_wines['type'],\n",
    "categories=[\"Red Wine\",\"White Wine\"])\n",
    "\n",
    "white_wines [\"type\"] = 'White Wine'\n",
    "white_wines['type'] = pd.Categorical(white_wines['type'],\n",
    "categories=[\"Red Wine\",\"White Wine\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest- unfiltered data set- smote after split- normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7776923076923077"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# merge datasets\n",
    "white_and_red = pd.merge(red_wines, white_wines, how = \"outer\")\n",
    "\n",
    "# Encoding\n",
    "enc = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "white_and_red['quality_label_encoded'] = enc.fit_transform(white_and_red[['quality_label']])\n",
    "\n",
    "#Feauture / Target split\n",
    "X=white_and_red.drop([\"type\",\"quality_label\",\"quality\",\"quality_label_encoded\"], axis=1)\n",
    "y= white_and_red[\"quality_label_encoded\"]\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Smote\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "## standarization\n",
    "norm = MinMaxScaler().fit(X_train_resampled)\n",
    "\n",
    "# transform training data\n",
    "X_train_resampled_norm = norm.transform(X_train_resampled)\n",
    "\n",
    "# transform testing data\n",
    "X_test_norm = norm.transform(X_test)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(X_train_resampled_norm, y_train_resampled)\n",
    "\n",
    "RF_preds = RF_clf.predict(X_test_norm)\n",
    "\n",
    "RF_acc = accuracy_score(y_test, RF_preds)\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest- Filtered data set with iqr- smote after split- normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white wine shape;  (4898, 14) \n",
      "filtered white wine shape:  (4015, 14)\n",
      "red wine shape;  (1599, 14) \n",
      "filtered red wine shape:  (1194, 14)\n"
     ]
    }
   ],
   "source": [
    "# filtered outliers\n",
    "white_wines_clean= white_wines.drop(\"quality\", axis=1)\n",
    "numeric_columns_white = white_wines_clean.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "white_wine_filtered= white_wines.copy()\n",
    "for column in numeric_columns_white.columns:\n",
    "        q1 = np.quantile(numeric_columns_white[column], 0.25)\n",
    "        q3 = np.quantile(numeric_columns_white[column], 0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        # Filter rows based on the column's outlier range\n",
    "        white_wine_filtered = white_wine_filtered[(white_wine_filtered[column] >= lower) & (white_wine_filtered[column] <= upper)]\n",
    "print(\"white wine shape; \", white_wines.shape, \"\\nfiltered white wine shape: \", white_wine_filtered.shape)\n",
    "\n",
    "red_wines_clean= red_wines.drop(\"quality\", axis=1)\n",
    "numeric_columns_red = red_wines_clean.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "red_wine_filtered= red_wines.copy()\n",
    "for column in numeric_columns_red.columns: \n",
    "        q1 = np.quantile(numeric_columns_red[column], 0.25)\n",
    "        q3 = np.quantile(numeric_columns_red[column], 0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        # Filter rows based on the column's outlier range\n",
    "        red_wine_filtered = red_wine_filtered[(red_wine_filtered[column] >= lower) & (red_wine_filtered[column] <= upper)]\n",
    "print(\"red wine shape; \", red_wines.shape, \"\\nfiltered red wine shape: \", red_wine_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "red_wine_filtered[\"residual_sugar\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792706333973128"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge datasets\n",
    "\n",
    "white_and_red_filtered = pd.merge(red_wine_filtered, white_wine_filtered, how = \"outer\")\n",
    "\n",
    "# Encoding\n",
    "enc = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "white_and_red_filtered['quality_label_encoded'] = enc.fit_transform(white_and_red_filtered[['quality_label']])\n",
    "\n",
    "#Feauture / Target split\n",
    "X_filtered=white_and_red_filtered.drop([\"type\",\"quality_label\",\"quality\",\"quality_label_encoded\"], axis=1)\n",
    "y_filtered= white_and_red_filtered[\"quality_label_encoded\"]\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "#Smote\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled_filtered, y_train_resampled_filtered = smote.fit_resample(X_train_filtered, y_train_filtered)\n",
    "\n",
    "## standarization\n",
    "norm = MinMaxScaler().fit(X_train_resampled_filtered)\n",
    "\n",
    "# transform training data\n",
    "X_train_resampled_filtered_norm = norm.transform(X_train_resampled_filtered)\n",
    "\n",
    "# transform testing data\n",
    "X_test_resampled_filtered_norm = norm.transform(X_test_filtered)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(X_train_resampled_filtered_norm, y_train_resampled_filtered)\n",
    "\n",
    "RF_preds = RF_clf.predict(X_test_resampled_filtered_norm)\n",
    "\n",
    "RF_acc = accuracy_score(y_test_filtered, RF_preds)\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White_and_red shape:  (6497, 15)\n",
      "X_filtered:  (5209, 11)\n",
      "X_train_filtered:  (4167, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"White_and_red shape: \", white_and_red.shape)\n",
    "print(\"X_filtered: \", X_filtered.shape)\n",
    "print(\"X_train_filtered: \", X_train_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest- Filtered data set with zscore- smote after split- normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtering with z score\n",
    "\n",
    "# create a copy of the columns(numeric values only) to iterate over ( if not it iterates over the newly created as well)\n",
    "\n",
    "\n",
    "\n",
    "white_wines_clean= white_wines.drop(\"quality\", axis=1)\n",
    "numeric_columns = white_wines_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "ww_filtered= white_wines.copy()\n",
    "z_score_dict = {}\n",
    "for x in numeric_columns:\n",
    "    z_score_dict[f'z_score_{x}'] = zscore(white_wines[x])\n",
    "\n",
    "\n",
    "# Create a DataFrame from the z_score_dict\n",
    "z_score_df = pd.DataFrame(z_score_dict, index=white_wines.index)\n",
    "\n",
    "# Concatenate the original DataFrame with the z_score DataFrame\n",
    "\n",
    "white_wines_with_zscores = pd.concat([ww_filtered, z_score_df], axis=1)\n",
    "\n",
    "# # Filter rows where the absolute value of all z_scores is less than 3\n",
    "z_score_columns = z_score_df.columns\n",
    "filtered_white_wines_z = white_wines_with_zscores[(white_wines_with_zscores[z_score_columns].abs() < 3).all(axis=1)]\n",
    "\n",
    "\n",
    "red_wines_clean= red_wines.drop(\"quality\", axis=1)\n",
    "numeric_columns_red = red_wines_clean.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "rw_filtered= red_wines.copy()\n",
    "z_score_dict_red = {}\n",
    "for x in numeric_columns_red:\n",
    "    z_score_dict_red[f'z_score_{x}'] = zscore(red_wines[x])\n",
    "\n",
    "\n",
    "# Create a DataFrame from the z_score_dict\n",
    "z_score_df_red = pd.DataFrame(z_score_dict_red, index=red_wines.index)\n",
    "\n",
    "# Concatenate the original DataFrame with the z_score DataFrame\n",
    "\n",
    "red_wines_with_zscores = pd.concat([rw_filtered, z_score_df_red], axis=1)\n",
    "\n",
    "# # Filter rows where the absolute value of all z_scores is less than 3\n",
    "z_score_columns_red = z_score_df_red.columns\n",
    "filtered_red_wines_z = red_wines_with_zscores[(red_wines_with_zscores[z_score_columns_red].abs() < 3).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7751677852348994"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge datasets\n",
    "white_and_red_filtered_z = pd.merge(filtered_white_wines_z, filtered_red_wines_z, how = \"outer\")\n",
    "\n",
    "# Encoding\n",
    "enc = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "white_and_red_filtered_z['quality_label_encoded'] = enc.fit_transform(white_and_red_filtered_z[['quality_label']])\n",
    "\n",
    "#Feauture / Target split\n",
    "X_filtered_z=white_and_red_filtered_z.drop([\"type\",\"quality_label\",\"quality\",\"quality_label_encoded\"], axis=1)\n",
    "y_filtered_z= white_and_red_filtered_z[\"quality_label_encoded\"]\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train_filtered_z, X_test_filtered_z, y_train_filtered_z, y_test_filtered_z = train_test_split(\n",
    "    X_filtered_z, y_filtered_z, test_size=0.2, random_state=42)\n",
    "\n",
    "#Smote\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled_filtered_z, y_train_resampled_filtered_z = smote.fit_resample(X_train_filtered_z, y_train_filtered_z)\n",
    "\n",
    "## standarization\n",
    "norm = MinMaxScaler().fit(X_train_resampled_filtered_z)\n",
    "\n",
    "# transform training data\n",
    "X_train_resampled_filtered_norm_z = norm.transform(X_train_resampled_filtered_z)\n",
    "\n",
    "# transform testing data\n",
    "X_test_resampled_filtered_norm_z = norm.transform(X_test_filtered_z)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(X_train_resampled_filtered_norm_z, y_train_resampled_filtered_z)\n",
    "\n",
    "RF_preds = RF_clf.predict(X_test_resampled_filtered_norm_z)\n",
    "\n",
    "RF_acc = accuracy_score(y_test_filtered_z, RF_preds)\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest- Filtered data set with iqr- (no smote) standarization (robust scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.809021113243762"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# copy of datasets\n",
    "X_train_stand = X_train_filtered.copy()\n",
    "X_test_stand = X_test_filtered.copy()\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_stand)\n",
    "    \n",
    "# transform the training data column\n",
    "X_train_stand = scaler.transform(X_train_stand)\n",
    "    \n",
    "# transform the testing data column\n",
    "X_test_stand = scaler.transform(X_test_stand)\n",
    "\n",
    "\n",
    "# ## standarization\n",
    "# norm = MinMaxScaler().fit(X_train_resampled_filtered)\n",
    "\n",
    "# # transform training data\n",
    "# X_train_resampled_filtered_norm = norm.transform(X_train_resampled_filtered)\n",
    "\n",
    "# # transform testing data\n",
    "# X_test_resampled_filtered_norm = norm.transform(X_test_filtered)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(X_train_stand, y_train_filtered)\n",
    "\n",
    "RF_preds = RF_clf.predict(X_test_stand)\n",
    "\n",
    "RF_acc = accuracy_score(y_test_filtered, RF_preds)\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest- Filtered data set with iqr- smote - standarization (robust scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7783109404990403"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy of datasets\n",
    "X_train_stand_resampled = X_train_resampled_filtered.copy()\n",
    "X_test_stand = X_test_filtered.copy()\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_stand_resampled)\n",
    "    \n",
    "# transform the training data column\n",
    "X_train_stand_resampled = scaler.transform(X_train_stand_resampled)\n",
    "    \n",
    "# transform the testing data column\n",
    "X_test_stand = scaler.transform(X_test_stand)\n",
    "\n",
    "\n",
    "# ## standarization\n",
    "# norm = MinMaxScaler().fit(X_train_resampled_filtered)\n",
    "\n",
    "# # transform training data\n",
    "# X_train_resampled_filtered_norm = norm.transform(X_train_resampled_filtered)\n",
    "\n",
    "# # transform testing data\n",
    "# X_test_resampled_filtered_norm = norm.transform(X_test_filtered)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(X_train_stand_resampled, y_train_resampled_filtered)\n",
    "\n",
    "RF_preds = RF_clf.predict(X_test_stand)\n",
    "\n",
    "RF_acc = accuracy_score(y_test_filtered, RF_preds)\n",
    "RF_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest with SMOTE (after split) & Stratified K-fold cross validation -normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracy: [0.8994910941475827, 0.8676844783715013, 0.8893129770992366, 0.8969465648854962, 0.9019108280254777, 0.8942675159235669, 0.8764331210191083, 0.89171974522293, 0.9019108280254777, 0.9095541401273886]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 90.95541401273886 %\n",
      "\n",
      "Minimum Accuracy: 86.76844783715013 %\n",
      "\n",
      "Overall Accuracy: 89.29231292847766 %\n",
      "\n",
      "Standard Deviation is: 0.01257277815753841\n",
      "\n",
      "Maximum Cohen-Kappa score that can be obtained from this model is: 86.42999999999999 %\n",
      "\n",
      "Maximum Balanced Accuracy That can be obtained from this model is: 90.95 %\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE (only on train set)#FIXME - need to do the smote inside the the loop, not before (the split)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_filtered, y_train_filtered)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(X_resampled) # normalizes for all X, instead of dividing in train and test.scaling after smote\n",
    "\n",
    "# Create  classifier object.\n",
    "# lr = linear_model.LogisticRegression()\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "  \n",
    "# Create StratifiedKFold object.\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "lst_balanced_accuracy_score=[]\n",
    "lst_kappa= []\n",
    "\n",
    "# .split generates indices to split data into training and test set.\n",
    "for train_index, test_index in skf.split(X_resampled,y_resampled):  \n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    rf.fit(x_train_fold, y_train_fold)\n",
    "    rf_pred = rf.predict(x_test_fold)\n",
    "    kappa = cohen_kappa_score(rf_pred, y_test_fold)\n",
    "    lst_kappa.append(round(kappa, 4))\n",
    "    balanced_acc_sc = balanced_accuracy_score(y_test_fold, rf_pred)\n",
    "    lst_balanced_accuracy_score.append(round(balanced_acc_sc,4))\n",
    "    lst_accu_stratified.append(rf.score(x_test_fold, y_test_fold))\n",
    "  \n",
    "# Print the output.\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "print('\\nMaximum Cohen-Kappa score that can be obtained from this model is:',\n",
    "      max(lst_kappa)*100, '%')\n",
    "print('\\nMaximum Balanced Accuracy That can be obtained from this model is:',\n",
    "      max(lst_balanced_accuracy_score)*100, '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: Random forest with SMOTE, Normalization & Stratified K-fold cross validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.89      0.89       262\n",
      "         1.0       0.88      0.86      0.87       261\n",
      "         2.0       0.97      1.00      0.98       262\n",
      "\n",
      "    accuracy                           0.91       785\n",
      "   macro avg       0.91      0.91      0.91       785\n",
      "weighted avg       0.91      0.91      0.91       785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Classification report\n",
    "print(\"Classification Report: Random forest with SMOTE, Normalization & Stratified K-fold cross validation\")\n",
    "print(classification_report(y_test_fold, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest with SMOTE (after split) & Stratified K-fold cross validation -standarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracy: [0.8893129770992366, 0.8702290076335878, 0.8829516539440203, 0.8969465648854962, 0.9031847133757962, 0.8955414012738854, 0.8777070063694268, 0.8929936305732484, 0.8955414012738854, 0.910828025477707]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 91.0828025477707 %\n",
      "\n",
      "Minimum Accuracy: 87.02290076335878 %\n",
      "\n",
      "Overall Accuracy: 89.1523638190629 %\n",
      "\n",
      "Standard Deviation is: 0.011996390368039298\n",
      "\n",
      "Maximum Cohen-Kappa score that can be obtained from this model is: 86.61999999999999 %\n",
      "\n",
      "Maximum Balanced Accuracy That can be obtained from this model is: 91.08000000000001 %\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# standarize\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_scaled = scaler.fit_transform(X_resampled) #  for all X, instead of dividing in train and test.scaling after smote\n",
    "\n",
    "# Create  classifier object.\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "  \n",
    "# Create StratifiedKFold object.\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "lst_balanced_accuracy_score=[]\n",
    "lst_kappa= []\n",
    "\n",
    "# .split generates indices to split data into training and test set.\n",
    "for train_index, test_index in skf.split(X_resampled,y_resampled):  \n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_resampled[train_index], y_resampled[test_index]\n",
    "    rf.fit(x_train_fold, y_train_fold)\n",
    "    rf_pred = rf.predict(x_test_fold)\n",
    "    kappa = cohen_kappa_score(rf_pred, y_test_fold)\n",
    "    lst_kappa.append(round(kappa, 4))\n",
    "    balanced_acc_sc = balanced_accuracy_score(y_test_fold, rf_pred)\n",
    "    lst_balanced_accuracy_score.append(round(balanced_acc_sc,4))\n",
    "    lst_accu_stratified.append(rf.score(x_test_fold, y_test_fold))\n",
    "  \n",
    "# Print the output.\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "print('\\nMaximum Cohen-Kappa score that can be obtained from this model is:',\n",
    "      max(lst_kappa)*100, '%')\n",
    "print('\\nMaximum Balanced Accuracy That can be obtained from this model is:',\n",
    "      max(lst_balanced_accuracy_score)*100, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_resampled shape:  (7854, 11)\n",
      "X_train shape:  (4167, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_resampled shape: \",X_resampled.shape)\n",
    "print(\"X_train shape: \", X_train_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: Random forest with SMOTE, Standarisation & Stratified K-fold cross validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.89      0.89       262\n",
      "         1.0       0.89      0.86      0.87       261\n",
      "         2.0       0.96      1.00      0.98       262\n",
      "\n",
      "    accuracy                           0.91       785\n",
      "   macro avg       0.91      0.91      0.91       785\n",
      "weighted avg       0.91      0.91      0.91       785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Classification report\n",
    "print(\"Classification Report: Random forest with SMOTE, Standarisation & Stratified K-fold cross validation\")\n",
    "print(classification_report(y_test_fold, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest with SMOTE & Undersampling / standarized / Stratified K-fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "over = SMOTE(random_state=42) # (sampling_strategy=0.1)\n",
    "under = RandomUnderSampler() #(sampling_strategy=0.5)\n",
    "steps = [('over', over), ('under', under), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of possible accuracy: [0.7937649880095923, 0.8105515587529976, 0.7865707434052758, 0.8225419664268585, 0.8273381294964028, 0.8201438848920863, 0.8465227817745803, 0.8293269230769231, 0.8004807692307693, 0.8052884615384616]\n",
      "\n",
      "Maximum Accuracy That can be obtained from this model is: 84.65227817745803 %\n",
      "\n",
      "Minimum Accuracy: 78.65707434052757 %\n",
      "\n",
      "Overall Accuracy: 81.42530206603948 %\n",
      "\n",
      "Standard Deviation is: 0.018296921413385347\n",
      "\n",
      "Maximum Cohen-Kappa score that can be obtained from this model is: 66.59 %\n",
      "\n",
      "Maximum Balanced Accuracy That can be obtained from this model is: 74.63 %\n"
     ]
    }
   ],
   "source": [
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# standarize\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_scaled = scaler.fit_transform(X_filtered) # normalizes for all X, instead of dividing in train and test.scaling after smote\n",
    "\n",
    "# Create  classifier object.\n",
    "# rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "  \n",
    "# Create StratifiedKFold object.\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "lst_balanced_accuracy_score=[]\n",
    "lst_kappa= []\n",
    "\n",
    "# .split generates indices to split data into training and test set.\n",
    "for train_index, test_index in skf.split(X_train_filtered,y_train_filtered):  \n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_filtered[train_index], y_filtered[test_index]\n",
    "    pipeline.fit(x_train_fold, y_train_fold)\n",
    "    pipeline_pred = pipeline.predict(x_test_fold)\n",
    "    kappa = cohen_kappa_score(pipeline_pred, y_test_fold)\n",
    "    lst_kappa.append(round(kappa, 4))\n",
    "    balanced_acc_sc = balanced_accuracy_score(y_test_fold, pipeline_pred)\n",
    "    lst_balanced_accuracy_score.append(round(balanced_acc_sc,4))\n",
    "    lst_accu_stratified.append(pipeline.score(x_test_fold, y_test_fold))\n",
    "  \n",
    "# Print the output.\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "print('\\nMaximum Cohen-Kappa score that can be obtained from this model is:',\n",
    "      max(lst_kappa)*100, '%')\n",
    "print('\\nMaximum Balanced Accuracy That can be obtained from this model is:',\n",
    "      max(lst_balanced_accuracy_score)*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine quality per type of wine with random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## white wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7920298879202988"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding\n",
    "enc = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "white_wine_filtered['quality_label_encoded'] = enc.fit_transform(white_wine_filtered[['quality_label']])\n",
    "\n",
    "#Feauture / Target split\n",
    "Xw_filtered=white_wine_filtered.drop([\"type\",\"quality_label\",\"quality\",\"quality_label_encoded\"], axis=1)\n",
    "yw_filtered= white_wine_filtered[\"quality_label_encoded\"]\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "Xw_train_filtered, Xw_test_filtered, yw_train_filtered, yw_test_filtered = train_test_split(\n",
    "    Xw_filtered, yw_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "#Smote\n",
    "smote = SMOTE(random_state=42)\n",
    "Xw_train_resampled_filtered, yw_train_resampled_filtered = smote.fit_resample(Xw_train_filtered, yw_train_filtered)\n",
    "\n",
    "## standarization\n",
    "norm = MinMaxScaler().fit(Xw_train_resampled_filtered)\n",
    "\n",
    "# transform training data\n",
    "Xw_train_resampled_filtered_norm = norm.transform(Xw_train_resampled_filtered)\n",
    "\n",
    "# transform testing data\n",
    "Xw_test_resampled_filtered_norm = norm.transform(Xw_test_filtered)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(Xw_train_resampled_filtered_norm, yw_train_resampled_filtered)\n",
    "\n",
    "RFw_preds = RF_clf.predict(Xw_test_resampled_filtered_norm)\n",
    "\n",
    "RFw_acc = accuracy_score(yw_test_filtered, RFw_preds)\n",
    "RFw_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[14, 16, 17, 20, 23, 35, 40, 54, 60, 62, 65, 67, 72, 79, 84, 85, 86, 88, 89, 96, 98, 99, 110, 115, 120, 124, 137, 141, 147, 154, 158, 159, 169, 178, 188, 194, 195, 196, 202, 207, 208, 209, 221, 224, 227, 230, 237, 238, 245, 250, 251, 267, 268, 269, 271, 273, 281, 294, 296, 297, 300, 302, 311, 315, 325, 357, 366, 372, 387, 392, 395, 402, 405, 407, 411, 415, 433, 439, 443, 450, 459, 464, 465, 468, 470, 478, 484, 496, 499, 501, 506, 507, 508, 509, 525, 528, 530, 541, 549, 551, 555, 556, 563, 564, 570, 580, 594, 602, 603, 612, 613, 614, 615, 620, 621, 624, 626, 646, 656, 659, 681, 683, 687, 694, 700, 729, 740, 745, 752, 754, 757, 758, 759, 763, 771, 772, 774, 775, 778, 780, 782, 792, 797, 800, 805, 811, 814, 819, 821, 830, 834, 847, 852, 853, 854, 855, 859, 862, 864, 866, 868, 870, 871, 873, 877, 878, 879, 890, 892, 913, 921, 922, 926, 928, 929, 937, 946, 948, 969, 970, 974, 979, 999, 1007, 1014, 1016, 1027, 1029, 1036, 1040, 1042, 1051, 1053, 1057, 1059, 1062, 1063, 1085, 1090, 1095, 1099, 1104, 1109, 1114, 1119, 1123, 1124, 1125, 1138, 1139, 1140, 1141, 1142, 1146, 1147, 1152, 1153, 1158, 1160, 1169, 1171, 1178, 1180, 1185, 1192, 1198, 1205, 1214, 1217, 1239, 1245, 1249, 1250, 1254, 1255, 1256, 1257, 1261, 1262, 1263, 1271, 1273, 1278, 1280, 1282, 1285, 1293, 1294, 1300, 1304, 1307, 1308, 1309, 1310, 1323, 1326, 1332, 1334, 1339, 1341, 1342, 1349, 1350, 1352, 1361, 1369, 1372, 1373, 1382, 1385, 1386, 1394, 1401, 1404, 1407, 1412, 1415, 1417, 1419, 1420, 1423, 1436, 1440, 1445, 1453, 1455, 1457, 1458, 1460, 1465, 1470, 1476, 1477, 1482, 1487, 1488, 1489, 1496, 1499, 1504, 1505, 1507, 1511, 1515, 1525, 1526, 1530, 1534, 1536, 1541, 1551, 1560, 1563, 1564, 1575, 1577, 1578, 1580, 1581, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1592, 1598, 1599, 1608, 1621, 1624, 1626, 1627, 1635, 1636, 1638, 1649, 1651, 1653, 1672, 1673, 1674, 1681, 1688, 1690, 1708, 1714, 1718, 1722, 1730, 1732, 1744, 1758, 1768, 1775, 1790, 1798, 1801, 1802, 1807, 1809, 1817, 1831, 1833, 1834, 1835, 1836, 1839, 1842, 1843, 1846, 1848, 1855, 1856, 1857, 1858, 1862, 1865, 1879, 1881, 1885, 1886, 1897, 1900, 1905, 1925, 1926, 1930, 1931, 1932, 1933, 1937, 1940, 1942, 1946, 1951, 1959, 1961, 1965, 1969, 1970, 1972, 1973, 1974, 1976, 1985, 1995, 1998, 2000, 2001, 2006, 2014, 2024, 2025, 2026, 2028, 2030, 2036, 2050, 2057, 2063, 2073, 2075, 2078, 2083, 2099, 2104, 2120, 2123, 2127, 2128, 2139, 2148, 2173, 2178, 2186, 2191, 2206, 2211, 2226, 2227, 2234, 2238, 2242, 2250, 2259, 2264, 2266, 2267, 2279, 2280, 2281, 2287, 2308, 2317, 2318, 2319, 2321, 2322, 2334, 2336, 2346, 2348, 2349, 2357, 2359, 2364, 2365, 2369, 2370, 2371, 2378, 2379, 2380, 2385, 2392, 2393, 2399, 2400, 2401, 2403, 2408, 2412, 2414, 2417, 2422, 2424, 2440, 2441, 2450, 2465, 2466, 2475, 2476, 2489, 2491, 2492, 2517, 2522, 2525, 2532, 2535, 2540, 2542, 2546, 2559, 2575, 2578, 2579, 2589, 2594, 2607, 2625, 2629, 2631, 2634, 2637, 2639, 2642, 2646, 2649, 2651, 2654, 2656, 2668, 2704, 2705, 2711, 2721, 2728, 2731, 2732, 2735, 2738, 2750, 2755, 2771, 2781, 2785, 2787, 2806, 2820, 2848, 2849, 2853, 2856, 2862, 2864, 2872, 2873, 2874, 2893, 2895, 2905, 2926, 2930, 2931, 2949, 2956, 2962, 2964, 3025, 3043, 3050, 3051, 3052, 3064, 3066, 3069, 3072, 3079, 3094, 3097, 3128, 3152, 3165, 3186, 3206, 3207, 3215, 3218, 3283, 3288, 3307, 3379, 3387, 3388, 3410, 3414, 3417, 3423, 3426, 3429, 3430, 3431, 3434, 3436, 3454, 3458, 3461, 3470, 3497, 3519, 3520, 3523, 3526, 3528, 3537, 3556, 3560, 3564, 3571, 3587, 3588, 3589, 3598, 3616, 3620, 3623, 3625, 3629, 3635, 3638, 3642, 3650, 3655, 3659, 3662, 3665, 3677, 3678, 3680, 3683, 3685, 3686, 3694, 3697, 3699, 3700, 3709, 3710, 3735, 3736, 3737, 3754, 3762, 3764, 3770, 3773, 3797, 3806, 3807, 3831, 3832, 3848, 3861, 3862, 3863, 3868, 3871, 3873, 3879, 3901, 3902, 3904, 3911, 3915, 3937, 3961, 3962, 3972, 3975, 3981, 3982, 3998, 3999, 4000, 4012] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m skf\u001b[38;5;241m.\u001b[39msplit(Xw_filtered,yw_filtered):  \n\u001b[1;32m     16\u001b[0m     xw_train_fold, xw_test_fold \u001b[38;5;241m=\u001b[39m xw_scaled[train_index], xw_scaled[test_index]\n\u001b[0;32m---> 17\u001b[0m     yw_train_fold, yw_test_fold \u001b[38;5;241m=\u001b[39m \u001b[43myw_filtered\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m, yw_filtered[test_index]\n\u001b[1;32m     18\u001b[0m     xw_train_resampled, yw_train_resampled \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(xw_train_fold, yw_train_fold)\n\u001b[1;32m     19\u001b[0m     rf\u001b[38;5;241m.\u001b[39mfit(xw_train_resampled, yw_train_resampled)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/series.py:1153\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/series.py:1180\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteger\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;66;03m# We need to decide whether to treat this as a positional indexer\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;66;03m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_should_fallback_to_positional:\n\u001b[0;32m-> 1180\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1182\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1183\u001b[0m             \u001b[38;5;66;03m# GH#50617\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.__getitem__ treating keys as positions is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1190\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/indexing.py:1420\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/indexing.py:1360\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1362\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[14, 16, 17, 20, 23, 35, 40, 54, 60, 62, 65, 67, 72, 79, 84, 85, 86, 88, 89, 96, 98, 99, 110, 115, 120, 124, 137, 141, 147, 154, 158, 159, 169, 178, 188, 194, 195, 196, 202, 207, 208, 209, 221, 224, 227, 230, 237, 238, 245, 250, 251, 267, 268, 269, 271, 273, 281, 294, 296, 297, 300, 302, 311, 315, 325, 357, 366, 372, 387, 392, 395, 402, 405, 407, 411, 415, 433, 439, 443, 450, 459, 464, 465, 468, 470, 478, 484, 496, 499, 501, 506, 507, 508, 509, 525, 528, 530, 541, 549, 551, 555, 556, 563, 564, 570, 580, 594, 602, 603, 612, 613, 614, 615, 620, 621, 624, 626, 646, 656, 659, 681, 683, 687, 694, 700, 729, 740, 745, 752, 754, 757, 758, 759, 763, 771, 772, 774, 775, 778, 780, 782, 792, 797, 800, 805, 811, 814, 819, 821, 830, 834, 847, 852, 853, 854, 855, 859, 862, 864, 866, 868, 870, 871, 873, 877, 878, 879, 890, 892, 913, 921, 922, 926, 928, 929, 937, 946, 948, 969, 970, 974, 979, 999, 1007, 1014, 1016, 1027, 1029, 1036, 1040, 1042, 1051, 1053, 1057, 1059, 1062, 1063, 1085, 1090, 1095, 1099, 1104, 1109, 1114, 1119, 1123, 1124, 1125, 1138, 1139, 1140, 1141, 1142, 1146, 1147, 1152, 1153, 1158, 1160, 1169, 1171, 1178, 1180, 1185, 1192, 1198, 1205, 1214, 1217, 1239, 1245, 1249, 1250, 1254, 1255, 1256, 1257, 1261, 1262, 1263, 1271, 1273, 1278, 1280, 1282, 1285, 1293, 1294, 1300, 1304, 1307, 1308, 1309, 1310, 1323, 1326, 1332, 1334, 1339, 1341, 1342, 1349, 1350, 1352, 1361, 1369, 1372, 1373, 1382, 1385, 1386, 1394, 1401, 1404, 1407, 1412, 1415, 1417, 1419, 1420, 1423, 1436, 1440, 1445, 1453, 1455, 1457, 1458, 1460, 1465, 1470, 1476, 1477, 1482, 1487, 1488, 1489, 1496, 1499, 1504, 1505, 1507, 1511, 1515, 1525, 1526, 1530, 1534, 1536, 1541, 1551, 1560, 1563, 1564, 1575, 1577, 1578, 1580, 1581, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1592, 1598, 1599, 1608, 1621, 1624, 1626, 1627, 1635, 1636, 1638, 1649, 1651, 1653, 1672, 1673, 1674, 1681, 1688, 1690, 1708, 1714, 1718, 1722, 1730, 1732, 1744, 1758, 1768, 1775, 1790, 1798, 1801, 1802, 1807, 1809, 1817, 1831, 1833, 1834, 1835, 1836, 1839, 1842, 1843, 1846, 1848, 1855, 1856, 1857, 1858, 1862, 1865, 1879, 1881, 1885, 1886, 1897, 1900, 1905, 1925, 1926, 1930, 1931, 1932, 1933, 1937, 1940, 1942, 1946, 1951, 1959, 1961, 1965, 1969, 1970, 1972, 1973, 1974, 1976, 1985, 1995, 1998, 2000, 2001, 2006, 2014, 2024, 2025, 2026, 2028, 2030, 2036, 2050, 2057, 2063, 2073, 2075, 2078, 2083, 2099, 2104, 2120, 2123, 2127, 2128, 2139, 2148, 2173, 2178, 2186, 2191, 2206, 2211, 2226, 2227, 2234, 2238, 2242, 2250, 2259, 2264, 2266, 2267, 2279, 2280, 2281, 2287, 2308, 2317, 2318, 2319, 2321, 2322, 2334, 2336, 2346, 2348, 2349, 2357, 2359, 2364, 2365, 2369, 2370, 2371, 2378, 2379, 2380, 2385, 2392, 2393, 2399, 2400, 2401, 2403, 2408, 2412, 2414, 2417, 2422, 2424, 2440, 2441, 2450, 2465, 2466, 2475, 2476, 2489, 2491, 2492, 2517, 2522, 2525, 2532, 2535, 2540, 2542, 2546, 2559, 2575, 2578, 2579, 2589, 2594, 2607, 2625, 2629, 2631, 2634, 2637, 2639, 2642, 2646, 2649, 2651, 2654, 2656, 2668, 2704, 2705, 2711, 2721, 2728, 2731, 2732, 2735, 2738, 2750, 2755, 2771, 2781, 2785, 2787, 2806, 2820, 2848, 2849, 2853, 2856, 2862, 2864, 2872, 2873, 2874, 2893, 2895, 2905, 2926, 2930, 2931, 2949, 2956, 2962, 2964, 3025, 3043, 3050, 3051, 3052, 3064, 3066, 3069, 3072, 3079, 3094, 3097, 3128, 3152, 3165, 3186, 3206, 3207, 3215, 3218, 3283, 3288, 3307, 3379, 3387, 3388, 3410, 3414, 3417, 3423, 3426, 3429, 3430, 3431, 3434, 3436, 3454, 3458, 3461, 3470, 3497, 3519, 3520, 3523, 3526, 3528, 3537, 3556, 3560, 3564, 3571, 3587, 3588, 3589, 3598, 3616, 3620, 3623, 3625, 3629, 3635, 3638, 3642, 3650, 3655, 3659, 3662, 3665, 3677, 3678, 3680, 3683, 3685, 3686, 3694, 3697, 3699, 3700, 3709, 3710, 3735, 3736, 3737, 3754, 3762, 3764, 3770, 3773, 3797, 3806, 3807, 3831, 3832, 3848, 3861, 3862, 3863, 3868, 3871, 3873, 3879, 3901, 3902, 3904, 3911, 3915, 3937, 3961, 3962, 3972, 3975, 3981, 3982, 3998, 3999, 4000, 4012] not in index'"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "scale = preprocessing.MinMaxScaler()\n",
    "xw_scaled = scale.fit_transform(Xw_filtered) # standarization for all X, instead of dividing in train and test.scaling after smote\n",
    "\n",
    "# Create  classifier object.\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "  \n",
    "# Create StratifiedKFold object.\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "lst_accu_stratified = []\n",
    "lst_balanced_accuracy_score=[]\n",
    "lst_kappa= []\n",
    "\n",
    "# .split generates indices to split data into training and test set.\n",
    "for train_index, test_index in skf.split(Xw_filtered,yw_filtered):  \n",
    "    xw_train_fold, xw_test_fold = xw_scaled[train_index], xw_scaled[test_index]\n",
    "    yw_train_fold, yw_test_fold = yw_filtered[train_index], yw_filtered[test_index]\n",
    "    xw_train_resampled, yw_train_resampled = smote.fit_resample(xw_train_fold, yw_train_fold)\n",
    "    rf.fit(xw_train_resampled, yw_train_resampled)\n",
    "    rfw_pred = rf.predict(xw_test_fold)\n",
    "    kappa = cohen_kappa_score(rfw_pred, yw_test_fold)\n",
    "    lst_kappa.append(round(kappa, 4))\n",
    "    balanced_acc_sc = balanced_accuracy_score(yw_test_fold, rfw_pred)\n",
    "    lst_balanced_accuracy_score.append(round(balanced_acc_sc,4))\n",
    "    lst_accu_stratified.append(rf.score(xw_test_fold, yw_test_fold))\n",
    "  \n",
    "# Print the output.\n",
    "print('List of possible accuracy:', lst_accu_stratified)\n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:',\n",
    "      max(lst_accu_stratified)*100, '%')\n",
    "print('\\nMinimum Accuracy:',\n",
    "      min(lst_accu_stratified)*100, '%')\n",
    "print('\\nOverall Accuracy:',\n",
    "      mean(lst_accu_stratified)*100, '%')\n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "print('\\nMaximum Cohen-Kappa score that can be obtained from this model is:',\n",
    "      max(lst_kappa)*100, '%')\n",
    "print('\\nMaximum Balanced Accuracy That can be obtained from this model is:',\n",
    "      max(lst_balanced_accuracy_score)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: Random forest with SMOTE & Stratified K-fold cross validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.89      0.89       262\n",
      "         1.0       0.88      0.85      0.86       261\n",
      "         2.0       0.95      1.00      0.97       262\n",
      "\n",
      "    accuracy                           0.91       785\n",
      "   macro avg       0.91      0.91      0.91       785\n",
      "weighted avg       0.91      0.91      0.91       785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Classification report\n",
    "print(\"Classification Report: Random forest with SMOTE & Stratified K-fold cross validation\")\n",
    "print(classification_report(y_test_fold, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## red wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7573221757322176"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding\n",
    "enc = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "red_wine_filtered['quality_label_encoded'] = enc.fit_transform(red_wine_filtered[['quality_label']])\n",
    "\n",
    "#Feauture / Target split\n",
    "Xr_filtered=red_wine_filtered.drop([\"type\",\"quality_label\",\"quality\",\"quality_label_encoded\"], axis=1)\n",
    "yr_filtered= red_wine_filtered[\"quality_label_encoded\"]\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "Xr_train_filtered, Xr_test_filtered, yr_train_filtered, yr_test_filtered = train_test_split(\n",
    "    Xr_filtered, yr_filtered, test_size=0.2, random_state=42)\n",
    "\n",
    "#Smote\n",
    "smote = SMOTE(random_state=42)\n",
    "Xr_train_resampled_filtered, yr_train_resampled_filtered = smote.fit_resample(Xr_train_filtered, yr_train_filtered)\n",
    "\n",
    "## standarization\n",
    "norm = MinMaxScaler().fit(Xr_train_resampled_filtered)\n",
    "\n",
    "# transform training data\n",
    "Xr_train_resampled_filtered_norm = norm.transform(Xr_train_resampled_filtered)\n",
    "\n",
    "# transform testing data\n",
    "Xr_test_resampled_filtered_norm = norm.transform(Xr_test_filtered)\n",
    "\n",
    "# define model\n",
    "RF_clf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "# fit model\n",
    "\n",
    "RF_clf.fit(Xr_train_resampled_filtered_norm, yr_train_resampled_filtered)\n",
    "\n",
    "RFr_preds = RF_clf.predict(Xr_test_resampled_filtered_norm)\n",
    "\n",
    "RFr_acc = accuracy_score(yr_test_filtered, RFr_preds)\n",
    "RFr_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeacademy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
